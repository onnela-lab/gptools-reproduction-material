{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de330688",
   "metadata": {},
   "source": [
    "# Density of *T. panamensis* on a 50 ha plot in Panama\n",
    "\n",
    "Trees on 50 ha plot on [Barro Colorado Island](https://en.wikipedia.org/wiki/Barro_Colorado_Island) have been [censused regularly since 1982](https://datadryad.org/stash/dataset/doi:10.15146/5xcp-0d46). The data are publicly available, and we use them here for a demonstration of a Gaussian process using the two-dimensional fast Fourier transform. For a given species, the data comprise the frequency $y$ of trees in each of 20 by 20 meter quadrants. For this example, we pick *T. panamensis* because its distribution is relatively heterogeneous over the plot. We load and visualize the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "mpl.style.use(\"../jss.mplstyle\")\n",
    "\n",
    "# Load the matrix of tree frequencies.\n",
    "frequency = np.loadtxt(f\"tachve.csv\", delimiter=\",\")\n",
    "nrows, ncols = frequency.shape\n",
    "delta = 20 / 1000  # Separation between adjacent plots in km.\n",
    "\n",
    "# Show the tree frequency in the plot.\n",
    "fig, ax = plt.subplots()\n",
    "extent = delta * (np.asarray([0, ncols, 0, nrows]) - 0.5)\n",
    "im = ax.imshow(frequency, extent=extent, origin=\"lower\")\n",
    "ax.set_xlabel(\"easting (km)\")\n",
    "ax.set_ylabel(\"northing (km)\")\n",
    "fig.colorbar(im, ax=ax, location=\"top\", label=\"tree frequency\", fraction=0.05)\n",
    "fig.tight_layout()\n",
    "frequency.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd835b",
   "metadata": {},
   "source": [
    "The FFT assumes periodic boundary conditions, but, of course, these do not apply to trees. We thus pad the domain to attenuate correlation between quadrants at opposite sides of the plot. A padding of 10 quadrants corresponds to 200 meters. The model is shown below.\n",
    "\n",
    "```{literalinclude} trees.stan\n",
    "   :language: stan\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1cb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptools.stan import compile_model\n",
    "import os\n",
    "\n",
    "\n",
    "# Set up the padded shapes.\n",
    "padding = 10\n",
    "padded_rows = nrows + padding\n",
    "padded_cols = ncols + padding\n",
    "\n",
    "# Sample a random training mask for later evaluation.\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "train_fraction = 0.8\n",
    "train_mask = np.random.uniform(size=frequency.shape) < train_fraction\n",
    "\n",
    "# Prepare the data for stan.\n",
    "data = {\n",
    "    \"num_rows\": nrows,\n",
    "    \"num_rows_padded\": padded_rows,\n",
    "    \"num_cols\": ncols,\n",
    "    \"num_cols_padded\": padded_cols,\n",
    "    # Use -1 for held-out data.\n",
    "    \"frequency\": np.where(train_mask, frequency, -1).astype(int),\n",
    "}\n",
    "\n",
    "# Compile and fit the model.\n",
    "model = compile_model(stan_file=\"trees.stan\")\n",
    "fit = model.sample(data, seed=seed, show_progress=False)\n",
    "diagnose = fit.diagnose()\n",
    "assert \"no problems detected\" in diagnose, diagnose\n",
    "print(diagnose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad76b9",
   "metadata": {},
   "source": [
    "The model is able to infer the underlying density of trees. As shown in the left panel below, the density follows within the original domain the data but is smoother. Outside the domain, in the padded region delineated by dashed lines, the posterior mean of the Gaussian process is very smooth because there are no data. As shown in the right panel, the posterior standard deviation is small where there is data and large in the padded area without data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a962f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "\n",
    "padded_extent = delta * (np.asarray([0, padded_cols, 0, padded_rows]) - 0.5)\n",
    "im1 = ax1.imshow(fit.f.mean(axis=0), extent=padded_extent, origin=\"lower\")\n",
    "im2 = ax2.imshow(fit.f.var(axis=0), extent=padded_extent, origin=\"lower\")\n",
    "fig.colorbar(im1, ax=ax1, location=\"top\", label=\"posterior mean $f$\")\n",
    "fig.colorbar(im2, ax=ax2, location=\"top\", label=\"posterior var $f$\")\n",
    "ax1.set_ylabel(\"padded northing (km)\")\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.set_xlabel(\"padded easting (km)\")\n",
    "    ax.axhline(nrows * delta, color=\"w\", ls=\"--\")\n",
    "    ax.axvline(ncols * delta, color=\"w\", ls=\"--\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af33f6f",
   "metadata": {},
   "source": [
    "We compare the GP-based inference with a simpler approach that employes a Gaussian filter to smooth the data. The estimate is\n",
    "$$\n",
    "\\hat{\\vec{y}}_\\lambda = \\frac{\\vec{g}_\\lambda\\ast\\left(\\vec{b}\\circ\\vec{y}\\right)}{\\vec{g}_\\lambda\\ast\\vec{b}},\n",
    "$$\n",
    "where $\\ast$ denotes convolution, $\\circ$ denotes the elementwise product, $\\vec{g}_\\lambda$ is a Gaussian filter with smoothing scale $\\lambda$, and $\\vec{b}$ is the binary mask indicating which data are available for training. Because the Gaussian filter only provides a point estimate, we cannot use the posterior predictive distribution to compare the two approaches. We instead use a scaled mean squared error\n",
    "$$\n",
    "S\\left(\\vec{y},\\hat{\\vec{y}}\\right) = \\exp\\hat{\\vec{f}} = \\frac{1}{m}\\sum_{j=1}^m \\frac{\\left(y_i-\\exp \\hat f_i\\right)^2}{\\max\\left(y_i,1\\right)},\n",
    "$$\n",
    "to compare the held out data $\\vec{y}$ with the prediction $\\hat{\\vec{y}}$. The scaling ensures large frequencies do not dominate the error measure because they [naturally have a larger variance](https://en.wikipedia.org/wiki/Poisson_distribution#Descriptive_statistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "def evaluate_scaled_error(actual, prediction, num_bs=1000):\n",
    "    \"\"\"\n",
    "    Evaluate scaled bootstrapped errors between held-out data and model predictions.\n",
    "    \"\"\"\n",
    "    idx = np.random.choice(actual.size, (num_bs, actual.size))\n",
    "    bs_actual = actual[idx]\n",
    "    bs_prediction = prediction[idx]\n",
    "    return (np.square(bs_actual - bs_prediction) / np.maximum(bs_actual, 1)).mean(axis=-1)\n",
    "\n",
    "\n",
    "def filter_estimate(frequency, train_mask, scale):\n",
    "    \"\"\"\n",
    "    Estimate held-out data using a Gaussian filter.\n",
    "    \"\"\"\n",
    "    smoothed_mask = gaussian_filter(train_mask.astype(float), scale)\n",
    "    smoothed_masked_frequency = gaussian_filter(np.where(train_mask, frequency, 0), scale)\n",
    "    return smoothed_masked_frequency / smoothed_mask\n",
    "\n",
    "\n",
    "# Evaluate predictions and errors using Gaussian filters at different scales.\n",
    "smoothed_errors = []\n",
    "sigmas = np.logspace(-0.8, 1)\n",
    "for sigma in sigmas:\n",
    "    smoothed_prediction = filter_estimate(frequency, train_mask, sigma)\n",
    "    smoothed_errors.append(evaluate_scaled_error(frequency[~train_mask],\n",
    "                                                 smoothed_prediction[~train_mask]))\n",
    "smoothed_errors = np.asarray(smoothed_errors)\n",
    "\n",
    "\n",
    "# Also evaluate the errors for the posterior median Gaussian process rates.\n",
    "rate = np.median(np.exp(fit.stan_variable(\"f\")[:, :nrows, :ncols]), axis=0)\n",
    "gp_errors = evaluate_scaled_error(frequency[~train_mask], rate[~train_mask])\n",
    "\n",
    "def plot_errors(smoothed_errors, gp_errors, ax=None):\n",
    "    \"\"\"\n",
    "    Plot bootstrapped errors for Gaussian filter and Gaussian process estimates.\n",
    "    \"\"\"\n",
    "    scale = delta * 1e3  # Show smoothing scale in meters.\n",
    "    ax = ax or plt.gca()\n",
    "\n",
    "    # Gaussian filter errors.\n",
    "    smoothed_loc = smoothed_errors.mean(axis=-1)\n",
    "    smoothed_scale = smoothed_errors.std(axis=-1)\n",
    "    line, = ax.plot(scale * sigmas, smoothed_loc, label=\"Gaussian\\nfilter\", color=\"C1\")\n",
    "    ax.fill_between(scale * sigmas, smoothed_loc - smoothed_scale, smoothed_loc + smoothed_scale,\n",
    "                    alpha=0.5, color=line.get_color())\n",
    "\n",
    "    # Gaussian process errors.\n",
    "    gp_loc = gp_errors.mean()\n",
    "    gp_scale = gp_errors.std()\n",
    "    line = ax.axhline(gp_loc, label=\"Gaussian\\nprocess\")\n",
    "    ax.axhspan(gp_loc - gp_scale, gp_loc + gp_scale, alpha=0.5, color=line.get_color())\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(r\"smoothing scale $\\lambda$\")\n",
    "    ax.set_ylabel(\"scaled mean-\\nsquared error $S$\")\n",
    "\n",
    "plot_errors(smoothed_errors, gp_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf533c",
   "metadata": {},
   "source": [
    "The bootstrapped scaled error for the Gaussian process is lower than the best scaled error for the Gaussian filter---even though the scale of the Gaussian filter was implicitly optimized on the held-out data.\n",
    "\n",
    "Let's assemble the parts to produce the figure in the accompanying publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8948fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "cmap = mpl.cm.viridis.copy()\n",
    "cmap.set_under(\"silver\")\n",
    "kwargs = {\n",
    "    \"origin\": \"lower\",\n",
    "    \"extent\": extent,\n",
    "    \"cmap\": cmap,\n",
    "    \"norm\": mpl.colors.Normalize(0, rate.max()),\n",
    "}\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_layout_engine(\"constrained\", w_pad=0.1)\n",
    "gs = fig.add_gridspec(1, 2, width_ratios=[4, 3])\n",
    "gs1 = mpl.gridspec.GridSpecFromSubplotSpec(3, 1, gs[0], height_ratios=[0.075, 1, 1])\n",
    "gs2 = mpl.gridspec.GridSpecFromSubplotSpec(2, 1, gs[1])\n",
    "\n",
    "cax = fig.add_subplot(gs1[0])\n",
    "ax1 = fig.add_subplot(gs1[1])\n",
    "ax1.set_ylabel(\"northing (km)\")\n",
    "ax1.set_xlabel(\"easting (km)\")\n",
    "im = ax1.imshow(data[\"frequency\"], **kwargs)\n",
    "\n",
    "ax2 = fig.add_subplot(gs1[2], sharex=ax1, sharey=ax1)\n",
    "ax2.set_xlabel(\"easting (km)\")\n",
    "ax2.set_ylabel(\"northing (km)\")\n",
    "im = ax2.imshow(rate, **kwargs)\n",
    "\n",
    "cb = fig.colorbar(im, cax=cax, extend=\"max\", orientation=\"horizontal\")\n",
    "cb.set_label(\"tree density\")\n",
    "cax.xaxis.set_ticks_position(\"top\")\n",
    "cax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "ax3 = fig.add_subplot(gs2[0])\n",
    "ax3.scatter(fit.length_scale * delta * 1e3, fit.sigma, marker=\".\",\n",
    "            alpha=0.25)\n",
    "ax3.set_xlabel(r\"correlation length $\\ell$ (m)\")\n",
    "ax3.set_ylabel(r\"marginal scale $\\sigma$\")\n",
    "\n",
    "ax4 = fig.add_subplot(gs2[1])\n",
    "plot_errors(smoothed_errors, gp_errors, ax4)\n",
    "\n",
    "ax4.legend(fontsize=\"small\", loc=(0.05, 0.425))\n",
    "\n",
    "fig.draw_without_rendering()\n",
    "\n",
    "text = ax1.get_yticklabels()[0]\n",
    "ax1.text(0, 0.5, \"(a)\", transform=text.get_transform(), ha=\"right\", va=\"center\")\n",
    "text = ax2.get_yticklabels()[0]\n",
    "ax2.text(0, 0.5, \"(c)\", transform=text.get_transform(), ha=\"right\", va=\"center\")\n",
    "ax3.text(0.05, 0.95, \"(b)\", va=\"top\", transform=ax3.transAxes)\n",
    "ax4.text(0.05, 0.95, \"(d)\", va=\"top\", transform=ax4.transAxes)\n",
    "\n",
    "fig.savefig(\"trees.pdf\", bbox_inches=\"tight\")\n",
    "fig.savefig(\"trees.png\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
